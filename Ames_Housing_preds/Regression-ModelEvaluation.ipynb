{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 2 Statistical Learning - Regression and Model Evaluation\r\n",
    "\r\n",
    "### Jonathan Gragg - East Section"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part One - Regression with the Ames Housing Data Set\r\n",
    "\r\n",
    "### 1. Load the Ames housing data. We will use the variables Sale_Price, Lot_Area, Year_Built, Gr_Liv_Area, Total_Bsmt_SF, Full_Bath to predict Sale_Price. Print the first few rows. (5 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\r\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, Lasso, Ridge\r\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_validate, train_test_split\r\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,\\\r\n",
    "    recall_score, precision_score, roc_curve, roc_auc_score, precision_recall_curve\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "ames = pd.read_csv('ames.csv')\r\n",
    "cols = ['Sale_Price', 'Lot_Area', 'Year_Built', 'Gr_Liv_Area', 'Total_Bsmt_SF', 'Full_Bath']\r\n",
    "data = ames[cols].copy()\r\n",
    "data = data.dropna()\r\n",
    "\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2930, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Create a vector \"y\" of the response variable and a matrix \"X\" of predictors. Standardize both so that each column has mean 0 and variance 1. Print the first few rows of X. (5 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "y = data.Sale_Price.values.reshape(-1,1)\r\n",
    "X = data.drop('Sale_Price', axis=1).values\r\n",
    "\r\n",
    "# rescalling the data to fit the linear model\r\n",
    "scaler = StandardScaler(with_mean=0,with_std=1)\r\n",
    "scaler.fit(X)\r\n",
    "X = scaler.transform(X)\r\n",
    "\r\n",
    "scaler = StandardScaler(with_mean=0,with_std=1)\r\n",
    "scaler.fit(y)\r\n",
    "y = scaler.transform(y)\r\n",
    "\r\n",
    "print('Predictor Matrix X')\r\n",
    "print(X[:4,])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictor Matrix X\n",
      "[[ 4.03240498 64.81438858  3.27646597  2.44957526  1.80882118]\n",
      " [ 1.47512152 64.84745715  1.77277386  2.00048646  1.80882118]\n",
      " [ 1.81083796 64.74825145  2.62948265  3.01433845  1.80882118]\n",
      " [ 1.4164822  65.07893711  4.17472415  4.78574426  3.61764237]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Fit 3 linear regression models to predict y from X. For each model, print the RMSE using the entire dataset (i.e. you don't need to split into training and testing). (10 pts)\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Model 1: Use all of the variables as predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "ln = LinearRegression()\r\n",
    "\r\n",
    "ln.fit(X,y)\r\n",
    "\r\n",
    "preds = ln.predict(X)\r\n",
    "mse = mean_squared_error(y,preds)\r\n",
    "rmse = np.sqrt(mse)\r\n",
    "\r\n",
    "print('Model 1 RMSE:', rmse)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1 RMSE: 0.5336628080215019\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Model 2: Use all of the variables, but also add interactions and quadratic terms."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "poly = PolynomialFeatures(degree=2)\r\n",
    "Z2 = poly.fit_transform(X)\r\n",
    "\r\n",
    "ln.fit(Z2,y)\r\n",
    "\r\n",
    "preds = ln.predict(Z2)\r\n",
    "mse = mean_squared_error(y,preds)\r\n",
    "rmse = np.sqrt(mse)\r\n",
    "\r\n",
    "print('Model 2 RMSE:', rmse)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 2 RMSE: 0.44834688197535655\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Model 3: Use all of the variables, but also add interactions, quadratic and cubic terms."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "poly = PolynomialFeatures(degree=3)\r\n",
    "Z3 = poly.fit_transform(X)\r\n",
    "\r\n",
    "ln.fit(Z3,y)\r\n",
    "\r\n",
    "preds = ln.predict(Z3)\r\n",
    "mse = mean_squared_error(y,preds)\r\n",
    "rmse = np.sqrt(mse)\r\n",
    "\r\n",
    "print('Model 3 RMSE:', rmse)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 3 RMSE: 0.37941846256257433\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Fit each model again, but this time use 10-fold cross validation. For each model fit, calculate the error (RMSE) from the training set and test set. Create a chart that summarizes the training and test error distributions for each model. (20 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2)\r\n",
    "\r\n",
    "cv = KFold(10, shuffle=True)\r\n",
    "\r\n",
    "train_scores = np.empty((10))\r\n",
    "validation_scores = np.empty((10))\r\n",
    "\r\n",
    "for k, (train_index, test_index) in enumerate(cv.split(X_train)):\r\n",
    "    ln = LinearRegression()\r\n",
    "    ln.fit(X_train[train_index], y_train[train_index])\r\n",
    "    train_scores[k] = np.sqrt(mean_squared_error(y_train[train_index],ln.predict(X_train[train_index])))\r\n",
    "    validation_scores[k] = np.sqrt(mean_squared_error(y_train[test_index],ln.predict(X_train[test_index])))\r\n",
    "\r\n",
    "mod1_t = train_scores\r\n",
    "mod1_v = validation_scores\r\n",
    "\r\n",
    "Z2_train, Z2_test, y_train, y_test = train_test_split(Z2,y,test_size=.2)\r\n",
    "\r\n",
    "cv = KFold(10, shuffle=True)\r\n",
    "\r\n",
    "train_scores = np.empty((10))\r\n",
    "validation_scores = np.empty((10))\r\n",
    "\r\n",
    "for k, (train_index, test_index) in enumerate(cv.split(Z2_train)):\r\n",
    "    ln = LinearRegression()\r\n",
    "    ln.fit(Z2_train[train_index], y_train[train_index])\r\n",
    "    train_scores[k] = np.sqrt(mean_squared_error(y_train[train_index],ln.predict(Z2_train[train_index])))\r\n",
    "    validation_scores[k] = np.sqrt(mean_squared_error(y_train[test_index],ln.predict(Z2_train[test_index])))\r\n",
    "\r\n",
    "mod2_t = train_scores\r\n",
    "mod2_v = validation_scores\r\n",
    "\r\n",
    "Z3_train, Z3_test, y_train, y_test = train_test_split(Z3,y,test_size=.2)\r\n",
    "\r\n",
    "cv = KFold(10, shuffle=True)\r\n",
    "\r\n",
    "train_scores = np.empty((10))\r\n",
    "validation_scores = np.empty((10))\r\n",
    "\r\n",
    "for k, (train_index, test_index) in enumerate(cv.split(Z3_train)):\r\n",
    "    ln = LinearRegression()\r\n",
    "    ln.fit(Z3_train[train_index], y_train[train_index])\r\n",
    "    train_scores[k] = np.sqrt(mean_squared_error(y_train[train_index],ln.predict(Z3_train[train_index])))\r\n",
    "    validation_scores[k] = np.sqrt(mean_squared_error(y_train[test_index],ln.predict(Z3_train[test_index])))\r\n",
    "\r\n",
    "mod3_t = train_scores\r\n",
    "mod3_v = validation_scores\r\n",
    "\r\n",
    "data = np.transpose(np.array([mod1_t,mod1_v,mod2_t,mod2_v,mod3_t,mod3_v]))\r\n",
    "pd.DataFrame(data,columns=['Mod 1 Train','Mod 1 Test','Mod 2 Train','Mod 2 Test','Mod 3 Train', 'Mod 3 Test'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Mod 1 Train  Mod 1 Test  Mod 2 Train  Mod 2 Test  Mod 3 Train  Mod 3 Test\n",
       "0     0.529691    0.497514     0.443622    0.544842     0.378318    0.380050\n",
       "1     0.489396    0.797855     0.454166    0.435293     0.369976    2.712255\n",
       "2     0.526776    0.524597     0.441420    0.552595     0.375695    0.560622\n",
       "3     0.533420    0.461601     0.448982    0.476746     0.380321    0.376968\n",
       "4     0.532112    0.473335     0.451402    0.456894     0.379260    0.360311\n",
       "5     0.531737    0.476110     0.456841    0.401003     0.371734    0.473280\n",
       "6     0.522611    0.561071     0.451949    0.449355     0.373590    0.420771\n",
       "7     0.528504    0.509143     0.450665    0.495133     0.376302    0.393961\n",
       "8     0.525820    0.532639     0.455415    0.420225     0.372987    0.617817\n",
       "9     0.538849    0.397521     0.445269    0.531981     0.360361    0.781991"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mod 1 Train</th>\n",
       "      <th>Mod 1 Test</th>\n",
       "      <th>Mod 2 Train</th>\n",
       "      <th>Mod 2 Test</th>\n",
       "      <th>Mod 3 Train</th>\n",
       "      <th>Mod 3 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.529691</td>\n",
       "      <td>0.497514</td>\n",
       "      <td>0.443622</td>\n",
       "      <td>0.544842</td>\n",
       "      <td>0.378318</td>\n",
       "      <td>0.380050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.489396</td>\n",
       "      <td>0.797855</td>\n",
       "      <td>0.454166</td>\n",
       "      <td>0.435293</td>\n",
       "      <td>0.369976</td>\n",
       "      <td>2.712255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.526776</td>\n",
       "      <td>0.524597</td>\n",
       "      <td>0.441420</td>\n",
       "      <td>0.552595</td>\n",
       "      <td>0.375695</td>\n",
       "      <td>0.560622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533420</td>\n",
       "      <td>0.461601</td>\n",
       "      <td>0.448982</td>\n",
       "      <td>0.476746</td>\n",
       "      <td>0.380321</td>\n",
       "      <td>0.376968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532112</td>\n",
       "      <td>0.473335</td>\n",
       "      <td>0.451402</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.379260</td>\n",
       "      <td>0.360311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.531737</td>\n",
       "      <td>0.476110</td>\n",
       "      <td>0.456841</td>\n",
       "      <td>0.401003</td>\n",
       "      <td>0.371734</td>\n",
       "      <td>0.473280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.522611</td>\n",
       "      <td>0.561071</td>\n",
       "      <td>0.451949</td>\n",
       "      <td>0.449355</td>\n",
       "      <td>0.373590</td>\n",
       "      <td>0.420771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.528504</td>\n",
       "      <td>0.509143</td>\n",
       "      <td>0.450665</td>\n",
       "      <td>0.495133</td>\n",
       "      <td>0.376302</td>\n",
       "      <td>0.393961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.525820</td>\n",
       "      <td>0.532639</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.420225</td>\n",
       "      <td>0.372987</td>\n",
       "      <td>0.617817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.538849</td>\n",
       "      <td>0.397521</td>\n",
       "      <td>0.445269</td>\n",
       "      <td>0.531981</td>\n",
       "      <td>0.360361</td>\n",
       "      <td>0.781991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. We want to predict the sale price of a home not included in this dataset. Write a short paragraph explaining which model you would recommend for this problem and why. (10 pts)\r\n",
    "\r\n",
    "Based on the RMSE output above I would recommend **Model 2** be used to predict housing prices. The reason is that Model 2 has the lowest RMSE on the test data set meaning that when validating it would be the most accurate model on data it was not trained on. Model 1 had a much higher RMSE and Model 3 looks to be overfit to the training data set and is not as applicable in a real world application."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part Two: Classification with the Heart Disease Data Set\r\n",
    "\r\n",
    "### 1. Load the heart disease data. The response variable, \"hd\", has been encoded as a binary variable (1 for heart disease, 0 without heart disease). Extract this as a vector and call this \"y\". Print the proportion of individuals in this data that have heart disease. (2 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "heart = pd.read_csv('heart.csv')\r\n",
    "y = heart.hd.values.reshape(-1,1)\r\n",
    "unique, counts = np.unique(y,return_counts=True)\r\n",
    "p = counts[1] / sum(counts)\r\n",
    "print('The proportion of individuals in this data with heart disease is', p.round(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The proportion of individuals in this data with heart disease is 0.459\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. We are going to fit a logistic regression model using the variables, age, trestbps, chol, thalach, sex, restecg, slope, and cp as predictors. Create a data matrix, X, of these predictors, and convert the categorical predictors to dummy variables (dropping the redundant column). Print the first few rows of X. (3 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cols = ['age', 'trestbps', 'chol', 'thalach', 'sex', 'restecg', 'slope','cp']\r\n",
    "data = heart[cols].copy()\r\n",
    "data = pd.get_dummies(data, drop_first=True)\r\n",
    "X = data.copy().values\r\n",
    "\r\n",
    "X[:4,]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 63, 145, 233, 150,   1,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [ 67, 160, 286, 108,   1,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [ 67, 120, 229, 129,   1,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [ 37, 130, 250, 187,   1,   1,   0,   0,   0,   0,   1,   0]],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Split the data (X and y) into training and testing datasets using a 60%/40% split, stratifying on the response variable. Standardize the training data (features) so that each column has mean 0 and variance 1. Apply this transformation to the test data set. Print the first few rows of each matrix. (10 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, stratify=y, random_state=1)\r\n",
    "\r\n",
    "num_columns = [0,1,2,3]\r\n",
    "scaler = StandardScaler(with_mean=0,with_std=1)\r\n",
    "scaler.fit(X_train[:,num_columns])\r\n",
    "X_train[:, num_columns] = scaler.transform(X_train[:,num_columns])\r\n",
    "\r\n",
    "scaler = StandardScaler(with_mean=0,with_std=1)\r\n",
    "scaler.fit(X_test[:,num_columns])\r\n",
    "X_test[:, num_columns] = scaler.transform(X_test[:,num_columns])\r\n",
    "\r\n",
    "print('Training Data set')\r\n",
    "print(X_train[:4,])\r\n",
    "\r\n",
    "print('Testing Data set')\r\n",
    "print(X_test[:4,])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data set\n",
      "[[5 6 2 7 0 1 0 1 0 0 1 0]\n",
      " [8 7 3 4 0 0 0 1 0 0 1 0]\n",
      " [4 7 3 7 1 0 0 1 0 0 1 0]\n",
      " [5 8 5 5 1 1 0 1 0 0 0 0]]\n",
      "Testing Data set\n",
      "[[5 8 3 7 1 1 0 0 1 0 1 0]\n",
      " [5 6 5 7 1 1 0 0 0 1 0 0]\n",
      " [6 7 5 6 1 1 0 1 0 0 1 0]\n",
      " [5 7 4 7 1 0 0 0 1 0 1 0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Fit two models to the training data. Print the fitted coefficients from each model. (10 pts)\r\n",
    "\r\n",
    "* Model 1: a logistic regression model (with no regularization)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr = LogisticRegression(penalty='none')\r\n",
    "\r\n",
    "lr.fit(X_train,y_train)\r\n",
    "lr.coef_"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jgragg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jgragg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.30237232,  0.32395209,  0.58167476, -0.5899138 ,  2.47577391,\n",
       "         0.69675204,  3.92039593,  0.16896536, -1.67906946, -2.34536669,\n",
       "        -2.3768187 , -2.67305566]])"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Model 2: an L1 regularized logistic regression model (choose the tuning parameter by using 10-fold cross validation on the training dataset).  (Hint: You might find the LogisticRegressionCV function useful for this part.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Cs = [.01,.1,1,10]\r\n",
    "lr = LogisticRegressionCV(Cs=Cs, cv=10, penalty='l1',solver='liblinear')\r\n",
    "lr.fit(X_train, y_train)\r\n",
    "lr.coef_"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jgragg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.2466351 ,  0.26668922,  0.5382863 , -0.63744265,  2.31826568,\n",
       "         0.60667455,  2.45089417,  0.05864553, -1.68132237, -2.27408609,\n",
       "        -2.27872498, -2.525491  ]])"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. For both models, make predictions on the test set, and compute the following metrics: (10 pts)\r\n",
    "\r\n",
    "* Model 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr = LogisticRegression(penalty='none')\r\n",
    "\r\n",
    "lr.fit(X_train,y_train)\r\n",
    "preds_1 = lr.predict(X_test)\r\n",
    "probs_1 = lr.predict_proba(X_test)[:, 1]\r\n",
    "\r\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_1).ravel()\r\n",
    "FPR = fp / (fp + tn)\r\n",
    "FDR = fp / (fp + tp)\r\n",
    "\r\n",
    "print('Accuracy:', lr.score(X_test, y_test).round(3))\r\n",
    "print('FPR: ', FPR.round(3))\r\n",
    "print('Recall: ', recall_score(y_test, preds_1).round(3))\r\n",
    "print('Precision: ', precision_score(y_test, preds_1).round(3))\r\n",
    "print('FDR: ', FDR.round(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.754\n",
      "FPR:  0.212\n",
      "Recall:  0.714\n",
      "Precision:  0.741\n",
      "FDR:  0.259\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jgragg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jgragg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Model 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Cs = [.01,.1,1,10]\r\n",
    "lr = LogisticRegressionCV(Cs=Cs, cv=10, penalty='l1',solver='liblinear')\r\n",
    "lr.fit(X_train,y_train)\r\n",
    "preds_2 = lr.predict(X_test)\r\n",
    "probs_2 = lr.predict_proba(X_test)[:, 1]\r\n",
    "\r\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_2).ravel()\r\n",
    "FPR = fp / (fp + tn)\r\n",
    "FDR = fp / (fp + tp)\r\n",
    "\r\n",
    "print('Accuracy:', lr.score(X_test, y_test).round(3))\r\n",
    "print('FPR: ', FPR.round(3))\r\n",
    "print('Recall: ', recall_score(y_test, preds_2).round(3))\r\n",
    "print('Precision: ', precision_score(y_test, preds_2).round(3))\r\n",
    "print('FDR: ', FDR.round(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jgragg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.754\n",
      "FPR:  0.227\n",
      "Recall:  0.732\n",
      "Precision:  0.732\n",
      "FDR:  0.268\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Plot the ROC curves and compute the AUC for each model. (10 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fpr1, tpr1, thresh1 = roc_curve(y_test, probs_1)\r\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, probs_2)\r\n",
    "\r\n",
    "import matplotlib as mpl\r\n",
    "mpl.style.use('seaborn')\r\n",
    "plt.plot(fpr1, tpr1, 'C1', label='Model 1')\r\n",
    "plt.plot(fpr2, tpr2, 'C2', label='Model 2')\r\n",
    "plt.plot([0,1],[0,1])\r\n",
    "plt.xlabel('FPR')\r\n",
    "plt.ylabel('TPR / Recall')\r\n",
    "plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ad830d8940>"
      ]
     },
     "metadata": {},
     "execution_count": 136
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"343.585156pt\" version=\"1.1\" viewBox=\"0 0 495.759844 343.585156\" width=\"495.759844pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-09-01T19:52:02.163999</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 343.585156 \r\nL 495.759844 343.585156 \r\nL 495.759844 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 42.159844 306.18 \r\nL 488.559844 306.18 \r\nL 488.559844 7.2 \r\nL 42.159844 7.2 \r\nz\r\n\" style=\"fill:#eaeaf2;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 62.450753 306.18 \r\nL 62.450753 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\"/>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(55.500753 320.337812)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 266 2259 \r\nQ 266 3072 433 3567 \r\nQ 600 4063 929 4331 \r\nQ 1259 4600 1759 4600 \r\nQ 2128 4600 2406 4451 \r\nQ 2684 4303 2865 4023 \r\nQ 3047 3744 3150 3342 \r\nQ 3253 2941 3253 2259 \r\nQ 3253 1453 3087 958 \r\nQ 2922 463 2592 192 \r\nQ 2263 -78 1759 -78 \r\nQ 1097 -78 719 397 \r\nQ 266 969 266 2259 \r\nz\r\nM 844 2259 \r\nQ 844 1131 1108 757 \r\nQ 1372 384 1759 384 \r\nQ 2147 384 2411 759 \r\nQ 2675 1134 2675 2259 \r\nQ 2675 3391 2411 3762 \r\nQ 2147 4134 1753 4134 \r\nQ 1366 4134 1134 3806 \r\nQ 844 3388 844 2259 \r\nz\r\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 581 0 \r\nL 581 641 \r\nL 1222 641 \r\nL 1222 0 \r\nL 581 0 \r\nz\r\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 143.614389 306.18 \r\nL 143.614389 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\"/>\r\n     <g id=\"text_2\">\r\n      <!-- 0.2 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(136.664389 320.337812)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 3222 541 \r\nL 3222 0 \r\nL 194 0 \r\nQ 188 203 259 391 \r\nQ 375 700 629 1000 \r\nQ 884 1300 1366 1694 \r\nQ 2113 2306 2375 2664 \r\nQ 2638 3022 2638 3341 \r\nQ 2638 3675 2398 3904 \r\nQ 2159 4134 1775 4134 \r\nQ 1369 4134 1125 3890 \r\nQ 881 3647 878 3216 \r\nL 300 3275 \r\nQ 359 3922 746 4261 \r\nQ 1134 4600 1788 4600 \r\nQ 2447 4600 2831 4234 \r\nQ 3216 3869 3216 3328 \r\nQ 3216 3053 3103 2787 \r\nQ 2991 2522 2730 2228 \r\nQ 2469 1934 1863 1422 \r\nQ 1356 997 1212 845 \r\nQ 1069 694 975 541 \r\nL 3222 541 \r\nz\r\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 224.778026 306.18 \r\nL 224.778026 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\"/>\r\n     <g id=\"text_3\">\r\n      <!-- 0.4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(217.828026 320.337812)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2069 0 \r\nL 2069 1097 \r\nL 81 1097 \r\nL 81 1613 \r\nL 2172 4581 \r\nL 2631 4581 \r\nL 2631 1613 \r\nL 3250 1613 \r\nL 3250 1097 \r\nL 2631 1097 \r\nL 2631 0 \r\nL 2069 0 \r\nz\r\nM 2069 1613 \r\nL 2069 3678 \r\nL 634 1613 \r\nL 2069 1613 \r\nz\r\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 305.941662 306.18 \r\nL 305.941662 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\"/>\r\n     <g id=\"text_4\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(298.991662 320.337812)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 3184 3459 \r\nL 2625 3416 \r\nQ 2550 3747 2413 3897 \r\nQ 2184 4138 1850 4138 \r\nQ 1581 4138 1378 3988 \r\nQ 1113 3794 959 3422 \r\nQ 806 3050 800 2363 \r\nQ 1003 2672 1297 2822 \r\nQ 1591 2972 1913 2972 \r\nQ 2475 2972 2870 2558 \r\nQ 3266 2144 3266 1488 \r\nQ 3266 1056 3080 686 \r\nQ 2894 316 2569 119 \r\nQ 2244 -78 1831 -78 \r\nQ 1128 -78 684 439 \r\nQ 241 956 241 2144 \r\nQ 241 3472 731 4075 \r\nQ 1159 4600 1884 4600 \r\nQ 2425 4600 2770 4297 \r\nQ 3116 3994 3184 3459 \r\nz\r\nM 888 1484 \r\nQ 888 1194 1011 928 \r\nQ 1134 663 1356 523 \r\nQ 1578 384 1822 384 \r\nQ 2178 384 2434 671 \r\nQ 2691 959 2691 1453 \r\nQ 2691 1928 2437 2201 \r\nQ 2184 2475 1800 2475 \r\nQ 1419 2475 1153 2201 \r\nQ 888 1928 888 1484 \r\nz\r\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 387.105298 306.18 \r\nL 387.105298 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\"/>\r\n     <g id=\"text_5\">\r\n      <!-- 0.8 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(380.155298 320.337812)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1131 2484 \r\nQ 781 2613 612 2850 \r\nQ 444 3088 444 3419 \r\nQ 444 3919 803 4259 \r\nQ 1163 4600 1759 4600 \r\nQ 2359 4600 2725 4251 \r\nQ 3091 3903 3091 3403 \r\nQ 3091 3084 2923 2848 \r\nQ 2756 2613 2416 2484 \r\nQ 2838 2347 3058 2040 \r\nQ 3278 1734 3278 1309 \r\nQ 3278 722 2862 322 \r\nQ 2447 -78 1769 -78 \r\nQ 1091 -78 675 323 \r\nQ 259 725 259 1325 \r\nQ 259 1772 486 2073 \r\nQ 713 2375 1131 2484 \r\nz\r\nM 1019 3438 \r\nQ 1019 3113 1228 2906 \r\nQ 1438 2700 1772 2700 \r\nQ 2097 2700 2305 2904 \r\nQ 2513 3109 2513 3406 \r\nQ 2513 3716 2298 3927 \r\nQ 2084 4138 1766 4138 \r\nQ 1444 4138 1231 3931 \r\nQ 1019 3725 1019 3438 \r\nz\r\nM 838 1322 \r\nQ 838 1081 952 856 \r\nQ 1066 631 1291 507 \r\nQ 1516 384 1775 384 \r\nQ 2178 384 2440 643 \r\nQ 2703 903 2703 1303 \r\nQ 2703 1709 2433 1975 \r\nQ 2163 2241 1756 2241 \r\nQ 1359 2241 1098 1978 \r\nQ 838 1716 838 1322 \r\nz\r\n\" id=\"ArialMT-38\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 468.268935 306.18 \r\nL 468.268935 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\"/>\r\n     <g id=\"text_6\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(461.318935 320.337812)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2384 0 \r\nL 1822 0 \r\nL 1822 3584 \r\nQ 1619 3391 1289 3197 \r\nQ 959 3003 697 2906 \r\nL 697 3450 \r\nQ 1169 3672 1522 3987 \r\nQ 1875 4303 2022 4600 \r\nL 2384 4600 \r\nL 2384 0 \r\nz\r\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- FPR -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(254.359844 334.198906)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 525 0 \r\nL 525 4581 \r\nL 3616 4581 \r\nL 3616 4041 \r\nL 1131 4041 \r\nL 1131 2622 \r\nL 3281 2622 \r\nL 3281 2081 \r\nL 1131 2081 \r\nL 1131 0 \r\nL 525 0 \r\nz\r\n\" id=\"ArialMT-46\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 494 0 \r\nL 494 4581 \r\nL 2222 4581 \r\nQ 2678 4581 2919 4538 \r\nQ 3256 4481 3484 4323 \r\nQ 3713 4166 3852 3881 \r\nQ 3991 3597 3991 3256 \r\nQ 3991 2672 3619 2267 \r\nQ 3247 1863 2275 1863 \r\nL 1100 1863 \r\nL 1100 0 \r\nL 494 0 \r\nz\r\nM 1100 2403 \r\nL 2284 2403 \r\nQ 2872 2403 3119 2622 \r\nQ 3366 2841 3366 3238 \r\nQ 3366 3525 3220 3729 \r\nQ 3075 3934 2838 4000 \r\nQ 2684 4041 2272 4041 \r\nL 1100 4041 \r\nL 1100 2403 \r\nz\r\n\" id=\"ArialMT-50\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 503 0 \r\nL 503 4581 \r\nL 2534 4581 \r\nQ 3147 4581 3465 4457 \r\nQ 3784 4334 3975 4021 \r\nQ 4166 3709 4166 3331 \r\nQ 4166 2844 3850 2509 \r\nQ 3534 2175 2875 2084 \r\nQ 3116 1969 3241 1856 \r\nQ 3506 1613 3744 1247 \r\nL 4541 0 \r\nL 3778 0 \r\nL 3172 953 \r\nQ 2906 1366 2734 1584 \r\nQ 2563 1803 2427 1890 \r\nQ 2291 1978 2150 2013 \r\nQ 2047 2034 1813 2034 \r\nL 1109 2034 \r\nL 1109 0 \r\nL 503 0 \r\nz\r\nM 1109 2559 \r\nL 2413 2559 \r\nQ 2828 2559 3062 2645 \r\nQ 3297 2731 3419 2920 \r\nQ 3541 3109 3541 3331 \r\nQ 3541 3656 3305 3865 \r\nQ 3069 4075 2559 4075 \r\nL 1109 4075 \r\nL 1109 2559 \r\nz\r\n\" id=\"ArialMT-52\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-46\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#ArialMT-50\"/>\r\n      <use x=\"127.783203\" xlink:href=\"#ArialMT-52\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 42.159844 292.59 \r\nL 488.559844 292.59 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\"/>\r\n     <g id=\"text_8\">\r\n      <!-- 0.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(21.259844 296.168906)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 42.159844 238.23 \r\nL 488.559844 238.23 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\"/>\r\n     <g id=\"text_9\">\r\n      <!-- 0.2 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(21.259844 241.808906)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 42.159844 183.87 \r\nL 488.559844 183.87 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\"/>\r\n     <g id=\"text_10\">\r\n      <!-- 0.4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(21.259844 187.448906)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 42.159844 129.51 \r\nL 488.559844 129.51 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\"/>\r\n     <g id=\"text_11\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(21.259844 133.088906)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 42.159844 75.15 \r\nL 488.559844 75.15 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\"/>\r\n     <g id=\"text_12\">\r\n      <!-- 0.8 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(21.259844 78.728906)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p6b73217f97)\" d=\"M 42.159844 20.79 \r\nL 488.559844 20.79 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\"/>\r\n     <g id=\"text_13\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(21.259844 24.368906)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- TPR / Recall -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(15.073594 187.557031)rotate(-90)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 1659 0 \r\nL 1659 4041 \r\nL 150 4041 \r\nL 150 4581 \r\nL 3781 4581 \r\nL 3781 4041 \r\nL 2266 4041 \r\nL 2266 0 \r\nL 1659 0 \r\nz\r\n\" id=\"ArialMT-54\" transform=\"scale(0.015625)\"/>\r\n       <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 0 -78 \r\nL 1328 4659 \r\nL 1778 4659 \r\nL 453 -78 \r\nL 0 -78 \r\nz\r\n\" id=\"ArialMT-2f\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2694 1069 \r\nL 3275 997 \r\nQ 3138 488 2766 206 \r\nQ 2394 -75 1816 -75 \r\nQ 1088 -75 661 373 \r\nQ 234 822 234 1631 \r\nQ 234 2469 665 2931 \r\nQ 1097 3394 1784 3394 \r\nQ 2450 3394 2872 2941 \r\nQ 3294 2488 3294 1666 \r\nQ 3294 1616 3291 1516 \r\nL 816 1516 \r\nQ 847 969 1125 678 \r\nQ 1403 388 1819 388 \r\nQ 2128 388 2347 550 \r\nQ 2566 713 2694 1069 \r\nz\r\nM 847 1978 \r\nL 2700 1978 \r\nQ 2663 2397 2488 2606 \r\nQ 2219 2931 1791 2931 \r\nQ 1403 2931 1139 2672 \r\nQ 875 2413 847 1978 \r\nz\r\n\" id=\"ArialMT-65\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2588 1216 \r\nL 3141 1144 \r\nQ 3050 572 2676 248 \r\nQ 2303 -75 1759 -75 \r\nQ 1078 -75 664 370 \r\nQ 250 816 250 1647 \r\nQ 250 2184 428 2587 \r\nQ 606 2991 970 3192 \r\nQ 1334 3394 1763 3394 \r\nQ 2303 3394 2647 3120 \r\nQ 2991 2847 3088 2344 \r\nL 2541 2259 \r\nQ 2463 2594 2264 2762 \r\nQ 2066 2931 1784 2931 \r\nQ 1359 2931 1093 2626 \r\nQ 828 2322 828 1663 \r\nQ 828 994 1084 691 \r\nQ 1341 388 1753 388 \r\nQ 2084 388 2306 591 \r\nQ 2528 794 2588 1216 \r\nz\r\n\" id=\"ArialMT-63\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2588 409 \r\nQ 2275 144 1986 34 \r\nQ 1697 -75 1366 -75 \r\nQ 819 -75 525 192 \r\nQ 231 459 231 875 \r\nQ 231 1119 342 1320 \r\nQ 453 1522 633 1644 \r\nQ 813 1766 1038 1828 \r\nQ 1203 1872 1538 1913 \r\nQ 2219 1994 2541 2106 \r\nQ 2544 2222 2544 2253 \r\nQ 2544 2597 2384 2738 \r\nQ 2169 2928 1744 2928 \r\nQ 1347 2928 1158 2789 \r\nQ 969 2650 878 2297 \r\nL 328 2372 \r\nQ 403 2725 575 2942 \r\nQ 747 3159 1072 3276 \r\nQ 1397 3394 1825 3394 \r\nQ 2250 3394 2515 3294 \r\nQ 2781 3194 2906 3042 \r\nQ 3031 2891 3081 2659 \r\nQ 3109 2516 3109 2141 \r\nL 3109 1391 \r\nQ 3109 606 3145 398 \r\nQ 3181 191 3288 0 \r\nL 2700 0 \r\nQ 2613 175 2588 409 \r\nz\r\nM 2541 1666 \r\nQ 2234 1541 1622 1453 \r\nQ 1275 1403 1131 1340 \r\nQ 988 1278 909 1158 \r\nQ 831 1038 831 891 \r\nQ 831 666 1001 516 \r\nQ 1172 366 1500 366 \r\nQ 1825 366 2078 508 \r\nQ 2331 650 2450 897 \r\nQ 2541 1088 2541 1459 \r\nL 2541 1666 \r\nz\r\n\" id=\"ArialMT-61\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 409 0 \r\nL 409 4581 \r\nL 972 4581 \r\nL 972 0 \r\nL 409 0 \r\nz\r\n\" id=\"ArialMT-6c\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-54\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#ArialMT-50\"/>\r\n      <use x=\"127.783203\" xlink:href=\"#ArialMT-52\"/>\r\n      <use x=\"200\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"227.783203\" xlink:href=\"#ArialMT-2f\"/>\r\n      <use x=\"255.566406\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"283.349609\" xlink:href=\"#ArialMT-52\"/>\r\n      <use x=\"355.566406\" xlink:href=\"#ArialMT-65\"/>\r\n      <use x=\"411.181641\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"461.181641\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"516.796875\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"539.013672\" xlink:href=\"#ArialMT-6c\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <path clip-path=\"url(#p6b73217f97)\" d=\"M 62.450753 292.59 \r\nL 62.450753 287.736429 \r\nL 62.450753 268.322143 \r\nL 68.599513 263.468571 \r\nL 68.599513 219.786429 \r\nL 74.748274 219.786429 \r\nL 74.748274 205.225714 \r\nL 80.897034 205.225714 \r\nL 80.897034 185.811429 \r\nL 93.194554 185.811429 \r\nL 93.194554 176.104286 \r\nL 99.343315 176.104286 \r\nL 99.343315 161.543571 \r\nL 111.640835 161.543571 \r\nL 111.640835 151.836429 \r\nL 123.938356 151.836429 \r\nL 123.938356 132.422143 \r\nL 136.235877 132.422143 \r\nL 136.235877 122.715 \r\nL 148.533397 122.715 \r\nL 148.533397 93.593571 \r\nL 154.682158 93.593571 \r\nL 154.682158 79.032857 \r\nL 166.979678 79.032857 \r\nL 166.979678 69.325714 \r\nL 185.425959 69.325714 \r\nL 185.425959 64.472143 \r\nL 210.021001 64.472143 \r\nL 210.021001 49.911429 \r\nL 259.211083 49.911429 \r\nL 259.211083 45.057857 \r\nL 265.359844 45.057857 \r\nL 265.359844 40.204286 \r\nL 271.508604 40.204286 \r\nL 271.508604 35.350714 \r\nL 332.996207 35.350714 \r\nL 332.996207 30.497143 \r\nL 351.442488 30.497143 \r\nL 357.591249 25.643571 \r\nL 357.591249 20.79 \r\nL 468.268935 20.79 \r\n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#p6b73217f97)\" d=\"M 62.450753 292.59 \r\nL 62.450753 287.736429 \r\nL 62.450753 268.322143 \r\nL 68.599513 263.468571 \r\nL 68.599513 210.079286 \r\nL 80.897034 210.079286 \r\nL 80.897034 180.957857 \r\nL 87.045794 180.957857 \r\nL 87.045794 171.250714 \r\nL 93.194554 171.250714 \r\nL 93.194554 151.836429 \r\nL 111.640835 151.836429 \r\nL 111.640835 142.129286 \r\nL 130.087116 142.129286 \r\nL 130.087116 127.568571 \r\nL 148.533397 127.568571 \r\nL 148.533397 93.593571 \r\nL 154.682158 93.593571 \r\nL 154.682158 79.032857 \r\nL 160.830918 79.032857 \r\nL 160.830918 69.325714 \r\nL 197.72348 69.325714 \r\nL 197.72348 64.472143 \r\nL 210.021001 64.472143 \r\nL 210.021001 54.765 \r\nL 228.467282 54.765 \r\nL 228.467282 49.911429 \r\nL 259.211083 49.911429 \r\nL 259.211083 45.057857 \r\nL 265.359844 45.057857 \r\nL 265.359844 40.204286 \r\nL 271.508604 40.204286 \r\nL 271.508604 35.350714 \r\nL 308.401166 35.350714 \r\nL 308.401166 30.497143 \r\nL 345.293728 30.497143 \r\nL 351.442488 25.643571 \r\nL 363.740009 25.643571 \r\nL 363.740009 20.79 \r\nL 468.268935 20.79 \r\n\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.75;\"/>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p6b73217f97)\" d=\"M 62.450753 292.59 \r\nL 468.268935 20.79 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 42.159844 306.18 \r\nL 42.159844 7.2 \r\n\" style=\"fill:none;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 488.559844 306.18 \r\nL 488.559844 7.2 \r\n\" style=\"fill:none;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 42.159844 306.18 \r\nL 488.559844 306.18 \r\n\" style=\"fill:none;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 42.159844 7.2 \r\nL 488.559844 7.2 \r\n\" style=\"fill:none;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"line2d_28\">\r\n     <path d=\"M 51.159844 19.857812 \r\nL 71.159844 19.857812 \r\n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\r\n    </g>\r\n    <g id=\"line2d_29\"/>\r\n    <g id=\"text_15\">\r\n     <!-- Model 1 -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(79.159844 23.357812)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 475 0 \r\nL 475 4581 \r\nL 1388 4581 \r\nL 2472 1338 \r\nQ 2622 884 2691 659 \r\nQ 2769 909 2934 1394 \r\nL 4031 4581 \r\nL 4847 4581 \r\nL 4847 0 \r\nL 4263 0 \r\nL 4263 3834 \r\nL 2931 0 \r\nL 2384 0 \r\nL 1059 3900 \r\nL 1059 0 \r\nL 475 0 \r\nz\r\n\" id=\"ArialMT-4d\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 213 1659 \r\nQ 213 2581 725 3025 \r\nQ 1153 3394 1769 3394 \r\nQ 2453 3394 2887 2945 \r\nQ 3322 2497 3322 1706 \r\nQ 3322 1066 3130 698 \r\nQ 2938 331 2570 128 \r\nQ 2203 -75 1769 -75 \r\nQ 1072 -75 642 372 \r\nQ 213 819 213 1659 \r\nz\r\nM 791 1659 \r\nQ 791 1022 1069 705 \r\nQ 1347 388 1769 388 \r\nQ 2188 388 2466 706 \r\nQ 2744 1025 2744 1678 \r\nQ 2744 2294 2464 2611 \r\nQ 2184 2928 1769 2928 \r\nQ 1347 2928 1069 2612 \r\nQ 791 2297 791 1659 \r\nz\r\n\" id=\"ArialMT-6f\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2575 0 \r\nL 2575 419 \r\nQ 2259 -75 1647 -75 \r\nQ 1250 -75 917 144 \r\nQ 584 363 401 755 \r\nQ 219 1147 219 1656 \r\nQ 219 2153 384 2558 \r\nQ 550 2963 881 3178 \r\nQ 1213 3394 1622 3394 \r\nQ 1922 3394 2156 3267 \r\nQ 2391 3141 2538 2938 \r\nL 2538 4581 \r\nL 3097 4581 \r\nL 3097 0 \r\nL 2575 0 \r\nz\r\nM 797 1656 \r\nQ 797 1019 1065 703 \r\nQ 1334 388 1700 388 \r\nQ 2069 388 2326 689 \r\nQ 2584 991 2584 1609 \r\nQ 2584 2291 2321 2609 \r\nQ 2059 2928 1675 2928 \r\nQ 1300 2928 1048 2622 \r\nQ 797 2316 797 1656 \r\nz\r\n\" id=\"ArialMT-64\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-4d\"/>\r\n      <use x=\"83.300781\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"138.916016\" xlink:href=\"#ArialMT-64\"/>\r\n      <use x=\"194.53125\" xlink:href=\"#ArialMT-65\"/>\r\n      <use x=\"250.146484\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"272.363281\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"300.146484\" xlink:href=\"#ArialMT-31\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_30\">\r\n     <path d=\"M 51.159844 34.003125 \r\nL 71.159844 34.003125 \r\n\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.75;\"/>\r\n    </g>\r\n    <g id=\"line2d_31\"/>\r\n    <g id=\"text_16\">\r\n     <!-- Model 2 -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(79.159844 37.503125)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#ArialMT-4d\"/>\r\n      <use x=\"83.300781\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"138.916016\" xlink:href=\"#ArialMT-64\"/>\r\n      <use x=\"194.53125\" xlink:href=\"#ArialMT-65\"/>\r\n      <use x=\"250.146484\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"272.363281\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"300.146484\" xlink:href=\"#ArialMT-32\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p6b73217f97\">\r\n   <rect height=\"298.98\" width=\"446.4\" x=\"42.159844\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. The default classification rule for logistic regression is to label heart disease if the predicted probability is greater than 0.5. Based on the metrics and curves you plotted for the best model, what are some reasons you might increase or lower this threshold? What are the tradeoffs between false-positives and false-negatives? (5 pts)\r\n",
    "\r\n",
    "When setting a threshold it is important to evaluate the problem you are trying to solve. For this scenario I would say it is okay to have more false positives than typical in order to diagnose as many cases of heart disease as possible. To adjust this you change the value of the threshold. Decreasing the threshold will create more positive predictions while increasing the threshold will create less positive predictions. \r\n",
    "\r\n",
    "For this scenerio I would not change the threshold. Increasing the false positive rate past 25% would create too many bad diagnoses. Decreasing the threshold would result in a lot of people getting falsely diagnosed with a serious disease. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "b68a8a6b96af4d8fd7fa1f3f8f4e1a7c76b6b97573f1f33bfec87c39108e4348"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}