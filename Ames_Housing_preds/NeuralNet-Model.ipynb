{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Statistical Learning Week 7 - Deep Neural Networks\r\n",
    "\r\n",
    "### Jonathan Gragg: East Section"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "#loading in relevant packages\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, Lasso, Ridge\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "# TensorFlow / Keras functions\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Dropout\r\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the Ames Housing dataset. Create dummy variables for all of the categorical features. Print the first few rows of this dataset. (5 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "ames = pd.read_csv('ames.csv')\r\n",
    "df = pd.get_dummies(ames, drop_first=True)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Year_Built</th>\n",
       "      <th>Year_Remod_Add</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>BsmtFin_SF_1</th>\n",
       "      <th>BsmtFin_SF_2</th>\n",
       "      <th>Bsmt_Unf_SF</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale_Type_ConLw</th>\n",
       "      <th>Sale_Type_New</th>\n",
       "      <th>Sale_Type_Oth</th>\n",
       "      <th>Sale_Type_VWD</th>\n",
       "      <th>Sale_Type_WD</th>\n",
       "      <th>Sale_Condition_AdjLand</th>\n",
       "      <th>Sale_Condition_Alloca</th>\n",
       "      <th>Sale_Condition_Family</th>\n",
       "      <th>Sale_Condition_Normal</th>\n",
       "      <th>Sale_Condition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>31770</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>1080</td>\n",
       "      <td>1656</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>11622</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>270</td>\n",
       "      <td>882</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>14267</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>406</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>11160</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1045</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>13830</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>928</td>\n",
       "      <td>928</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lot_Frontage  Lot_Area  Year_Built  Year_Remod_Add  Mas_Vnr_Area  \\\n",
       "0           141     31770        1960            1960           112   \n",
       "1            80     11622        1961            1961             0   \n",
       "2            81     14267        1958            1958           108   \n",
       "3            93     11160        1968            1968             0   \n",
       "4            74     13830        1997            1998             0   \n",
       "\n",
       "   BsmtFin_SF_1  BsmtFin_SF_2  Bsmt_Unf_SF  Total_Bsmt_SF  First_Flr_SF  ...  \\\n",
       "0             2             0          441           1080          1656  ...   \n",
       "1             6           144          270            882           896  ...   \n",
       "2             1             0          406           1329          1329  ...   \n",
       "3             1             0         1045           2110          2110  ...   \n",
       "4             3             0          137            928           928  ...   \n",
       "\n",
       "   Sale_Type_ConLw  Sale_Type_New  Sale_Type_Oth  Sale_Type_VWD  \\\n",
       "0                0              0              0              0   \n",
       "1                0              0              0              0   \n",
       "2                0              0              0              0   \n",
       "3                0              0              0              0   \n",
       "4                0              0              0              0   \n",
       "\n",
       "   Sale_Type_WD   Sale_Condition_AdjLand  Sale_Condition_Alloca  \\\n",
       "0              1                       0                      0   \n",
       "1              1                       0                      0   \n",
       "2              1                       0                      0   \n",
       "3              1                       0                      0   \n",
       "4              1                       0                      0   \n",
       "\n",
       "   Sale_Condition_Family  Sale_Condition_Normal  Sale_Condition_Partial  \n",
       "0                      0                      1                       0  \n",
       "1                      0                      1                       0  \n",
       "2                      0                      1                       0  \n",
       "3                      0                      1                       0  \n",
       "4                      0                      1                       0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Use \"Sale_Price\" to create a column vector of responses (y). Create a feature matrix (X) using all of the other variables. (5 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "y = df['Sale_Price'].values\r\n",
    "X = df.drop('Sale_Price',axis=1).values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Split the data into training, validation, and testing sets using a 60/20/20 split. Print the dimensions of each of the feature matrices. (5 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=1)\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.25, random_state=2019)\r\n",
    "print(\"X_train\",\"X_valid\",\"X_test\",\"y_train\",\"y_valid\",\"y_test\")\r\n",
    "print(X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train X_valid X_test y_train y_valid y_test\n",
      "(1758, 306) (586, 306) (586, 306) (1758,) (586,) (586,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Standardize both the features and responses from the training set. Apply the appropriate transformation to the validation and test sets. (10 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "#training data set\r\n",
    "scaler.fit(X_train)\r\n",
    "X_train = scaler.transform(X_train)\r\n",
    "scaler.fit(y_train.reshape(-1,1))\r\n",
    "y_train = scaler.transform(y_train.reshape(-1,1))\r\n",
    "\r\n",
    "#validation data set\r\n",
    "scaler.fit(X_valid)\r\n",
    "X_valid = scaler.transform(X_valid)\r\n",
    "scaler.fit(y_valid.reshape(-1,1))\r\n",
    "y_valid = scaler.transform(y_valid.reshape(-1,1))\r\n",
    "\r\n",
    "#testing data set\r\n",
    "scaler.fit(X_test)\r\n",
    "X_test = scaler.transform(X_test)\r\n",
    "scaler.fit(y_test.reshape(-1,1))\r\n",
    "y_test = scaler.transform(y_test.reshape(-1,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Before we fit a neural network, we'll first try a simpler model using the Lasso. Fit a Lasso regression model to the training set using alpha=.05 as the tuning parameter. This should be a good choice assuming the data has been standardized. Calculate the mean squared error (MSE) on the training, validation, and test sets. (10 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "ls = Lasso(alpha=0.5)\r\n",
    "ls.fit(X_train,y_train)\r\n",
    "preds_tr = ls.predict(X_train)\r\n",
    "print(\"Training MSE:\",mean_squared_error(y_train,preds_tr))\r\n",
    "preds_v = ls.predict(X_valid)\r\n",
    "print(\"Validation MSE:\",mean_squared_error(y_valid,preds_v))\r\n",
    "preds_te = ls.predict(X_test)\r\n",
    "print(\"Testing MSE:\",mean_squared_error(y_test,preds_te))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training MSE: 0.7181094358737364\n",
      "Validation MSE: 0.7174834930146333\n",
      "Testing MSE: 0.694076354802436\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Fit a neural network using the following architecture, and print the output from training. (15 pts)\r\n",
    "* Use 2 hidden layers with 50 neurons each;\r\n",
    "* Use ReLU activation functions for the hidden layers;\r\n",
    "* Use a linear activation function for the output layer;\r\n",
    "* Use MSE for the loss function;\r\n",
    "* Use the Adam optimizer;\r\n",
    "* Use 100 epochs;\r\n",
    "* Use a batch size of 100."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "model = Sequential()\r\n",
    "model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1], )))\r\n",
    "model.add(Dense(50, activation='relu'))\r\n",
    "model.add(Dense(1, activation='linear'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss=keras.losses.MeanSquaredError())\r\n",
    "\r\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=100, \r\n",
    "                    validation_data=(X_valid, y_valid),verbose=0)\r\n",
    "\r\n",
    "model.predict(X_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.7966611 ],\n",
       "       [-0.6121895 ],\n",
       "       [ 0.03458093],\n",
       "       ...,\n",
       "       [ 1.6824687 ],\n",
       "       [-0.6412039 ],\n",
       "       [-1.1029694 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Print the MSE from the test set using the model in (6). How does this compare to the Lasso? (5 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "pred_te = model.predict(X_test)\r\n",
    "print(\"Test MSE:\",mean_squared_error(y_test,pred_te))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test MSE: 0.12926920123250632\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "the MSE for the neural network was significantly lower than the MSE using the Lasso regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Optimize the neural network you fit in Q6 to get a better MSE than the Lasso model. You should use the validation set to ensure you're not overfitting. Print the output from training this model. Consider changing the following components to improve performance (it's not required to change all of these). (20 pts)\r\n",
    "* Number of layers;\r\n",
    "* Number of neurons per layer;\r\n",
    "* Number of epochs and batch size;\r\n",
    "* Activation functions of hidden layers;\r\n",
    "* Adding regularization (Dropout layers, L1/L2 penalties, early stopping)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "model = Sequential()\r\n",
    "model.add(Dense(100, activation='relu', input_shape=(X_train.shape[1], ),kernel_regularizer=keras.regularizers.l2(.001)))\r\n",
    "model.add(Dense(50, activation='relu'))\r\n",
    "model.add(Dense(1, activation='linear'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss=keras.losses.MeanSquaredError())\r\n",
    "\r\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\r\n",
    "\r\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=100, \r\n",
    "                    validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=0)\r\n",
    "\r\n",
    "model.predict(X_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.8135778 ],\n",
       "       [-0.5656206 ],\n",
       "       [ 0.06807338],\n",
       "       ...,\n",
       "       [ 1.6967919 ],\n",
       "       [-0.6295544 ],\n",
       "       [-1.1139355 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Print the MSE from the test set using the model in Q8. (5 pts) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "pred_te = model.predict(X_test)\r\n",
    "print(\"Test MSE:\",mean_squared_error(y_test,pred_te))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test MSE: 0.09807123972995355\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Plot the training and validation MSE for each epoch. (10 pts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "plt.plot(history.history['loss'], label='Training MSE')\r\n",
    "plt.plot(history.history['val_loss'], label='Validation MSE')\r\n",
    "plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22819495c70>"
      ]
     },
     "metadata": {},
     "execution_count": 89
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11. In a few sentences, describe how you optimized the model in Q8. Did you find that changing certain components had bigger effects on the error rate? (5 pts)\r\n",
    "I added L2 regularization and doubled the number of neurons in the first hidden layer. That by itself decreased the MSE in half. But I was nervous I was overfitting the model so applied early stopping to the model and after than I ended with a slightly higher MSE but still lower than the first neural net."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12. How do you know that your model is not overfitting? That is, how do you know you didn't get lucky on the test set? (5 pts)\r\n",
    "\r\n",
    "When I'm looking at the graph from Q10, I'm seeing the validation MSE steadily decreasing. If I was overfitting to the training data set I would have expected to see leveling off of the validation MSE while the training MSE continued to decrease. I also applied early stopping to make the likelihood of overfitting to training extremely low."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "b68a8a6b96af4d8fd7fa1f3f8f4e1a7c76b6b97573f1f33bfec87c39108e4348"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}